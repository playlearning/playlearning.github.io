(window.webpackJsonp=window.webpackJsonp||[]).push([[6],{218:function(e){e.exports=[{event:"Session 1",date:"-",description:"Q-learning",slide:{title:"Slide",link:""},readings:[{title:"Learning from delayed rewards",link:"https://s3.amazonaws.com/academia.edu.documents/50360235/Learning_from_delayed_rewards_20161116-28282-v2pwvq.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1556185559&Signature=MF%2FnJBqKdoLw3vtambRt96bdW%2FM%3D&response-content-disposition=inline%3B%20filename%3DLearning_from_delayed_rewards.pdf",year:1989,remark:"Watkins' thesis"},{title:"Q-learning",link:"https://link.springer.com/content/pdf/10.1007/BF00992698.pdf",year:1992,remark:""},{title:"Playing Atari with Deep Reinforcement Learning",link:"https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf",year:2013,remark:"DQN",stress:!0},{title:"Deep Recurrent Q-Learning for Partially Observable MDPs",link:"https://arxiv.org/abs/1507.06527",year:2015,remark:"Deep Recurrent Q-Learning"},{title:"Dueling Network Architectures for Deep Reinforcement Learning",link:"https://arxiv.org/abs/1511.06581",year:2015,remark:"Dueling DQN"},{title:"Deep Reinforcement Learning with Double Q-learning",link:"https://arxiv.org/abs/1509.06461",year:2015,remark:"Double DQN",stress:!0},{title:"Prioritized Experience Replay",link:"https://arxiv.org/abs/1511.05952",year:2015,remark:"PER"},{title:"Rainbow: Combining Improvements in Deep Reinforcement Learning",link:"https://arxiv.org/abs/1710.02298",year:2017,remark:"Rainbow DQN",stress:!0}]}]},223:function(e,t,r){"use strict";r.r(t);var n=r(218),a={data:function(){return{items:n}}},i=r(2),s=Object(i.a)(a,function(){var e=this,t=e.$createElement,r=e._self._c||t;return r("table",{staticClass:"table"},[e._m(0),e._v(" "),r("tbody",e._l(e.items,function(t){return r("tr",[r("td",{attrs:{scope:"row"}},[e._v(e._s(t.event))]),e._v(" "),r("td",[e._v(e._s(t.date))]),e._v(" "),r("td",[e._v("\n                "+e._s(t.description)+"\n            ")]),e._v(" "),r("td",[r("ul",{staticStyle:{"margin-block-start":"0"}},e._l(t.readings,function(t){return r("li",[t.year||t.remark?r("span",[e._v("[")]):e._e(),t.year?r("span",[e._v(e._s(t.year))]):e._e(),t.year&&t.remark?r("span",[e._v(", ")]):e._e(),t.remark?r("span",[e._v(e._s(t.remark))]):e._e(),t.year||t.remark?r("span",[e._v("]")]):e._e(),e._v(" "),r("a",{attrs:{href:t.link}},[e._v(e._s(t.title))])])}),0)])])}),0)])},[function(){var e=this.$createElement,t=this._self._c||e;return t("thead",[t("tr",{staticClass:"active"},[t("th",{staticClass:"col"},[this._v("Event")]),this._v(" "),t("th",{staticClass:"col"},[this._v("Date")]),this._v(" "),t("th",{staticClass:"col"},[this._v("Description")]),this._v(" "),t("th",{staticClass:"col"},[this._v("Session Materials")])])])}],!1,null,null,null);t.default=s.exports}}]);