(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{261:function(e,r,t){"use strict";t.r(r);var n=t(2),a=Object(n.a)({},function(){var e=this,r=e.$createElement,t=e._self._c||r;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h1",{attrs:{id:"deep-reinforcement-learning-seminar"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#deep-reinforcement-learning-seminar","aria-hidden":"true"}},[e._v("#")]),e._v(" Deep Reinforcement Learning Seminar")]),e._v(" "),t("h2",{attrs:{id:"sessions"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#sessions","aria-hidden":"true"}},[e._v("#")]),e._v(" Sessions")]),e._v(" "),t("div",{staticClass:"tip custom-block"},[t("p",[t("strong",[e._v("Target: Learning reinforcement learning basics and advances within 10 sessions in 2 months.")])])]),e._v(" "),t("Sessions",{attrs:{src:"/json/rl_sessions.json"}}),e._v(" "),t("h2",{attrs:{id:"comparison-of-different-schedules"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#comparison-of-different-schedules","aria-hidden":"true"}},[e._v("#")]),e._v(" Comparison of different schedules")]),e._v(" "),t("cs294-112"),e._v(" "),t("rl-60days"),e._v(" "),t("h2",{attrs:{id:"materials"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#materials","aria-hidden":"true"}},[e._v("#")]),e._v(" Materials")]),e._v(" "),t("ol",[t("li",[e._v("链接\n"),t("ol",[t("li",[e._v("OpenAI Key papers list: "),t("a",{attrs:{href:"https://spinningup.openai.com/en/latest/spinningup/keypapers.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://spinningup.openai.com/en/latest/spinningup/keypapers.html"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("A Beginner's Guide to Deep Reinforcement Learning： "),t("a",{attrs:{href:"https://skymind.ai/wiki/deep-reinforcement-learning",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://skymind.ai/wiki/deep-reinforcement-learning"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Awesome Reinforcement Learning: "),t("a",{attrs:{href:"https://github.com/aikorea/awesome-rl",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://github.com/aikorea/awesome-rl"),t("OutboundLink")],1),e._v(" （2018.12.9）")]),e._v(" "),t("li",[t("a",{attrs:{href:"https://github.com/tigerneil/awesome-deep-rl",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://github.com/tigerneil/awesome-deep-rl"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Dopamine: "),t("a",{attrs:{href:"https://github.com/google/dopamine",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://github.com/google/dopamine"),t("OutboundLink")],1)])])]),e._v(" "),t("li",[e._v("公开课：\n"),t("ol",[t("li",[e._v("总目录： "),t("a",{attrs:{href:"https://github.com/kmario23/deep-learning-drizzle#balloon-reinforcement-learning-hotsprings-video_game",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://github.com/kmario23/deep-learning-drizzle#balloon-reinforcement-learning-hotsprings-video_game"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Berkeley： "),t("a",{attrs:{href:"http://rail.eecs.berkeley.edu/deeprlcourse/",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://rail.eecs.berkeley.edu/deeprlcourse/"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Berkeley Bootcamp： "),t("a",{attrs:{href:"https://sites.google.com/view/deep-rl-bootcamp/lectures",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://sites.google.com/view/deep-rl-bootcamp/lectures"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Standord： "),t("a",{attrs:{href:"http://web.stanford.edu/class/cs234/index.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://web.stanford.edu/class/cs234/index.html"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("CMU： "),t("a",{attrs:{href:"http://www.andrew.cmu.edu/course/10-703/",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://www.andrew.cmu.edu/course/10-703/"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("David Silver： "),t("a",{attrs:{href:"http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("OpenAI: "),t("strong",[t("a",{attrs:{href:"https://spinningup.openai.com/en/latest/user/introduction.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://spinningup.openai.com/en/latest/user/introduction.html"),t("OutboundLink")],1)])]),e._v(" "),t("li",[e._v("貌似有趣："),t("a",{attrs:{href:"https://simoninithomas.github.io/Deep_reinforcement_learning_Course/",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://simoninithomas.github.io/Deep_reinforcement_learning_Course/"),t("OutboundLink")],1)])])]),e._v(" "),t("li",[e._v("教材：\n"),t("ol",[t("li",[t("strong",[e._v("Reinforcement Learning: An Introduction, Sutton and Barto, 2018")]),e._v(" "),t("ol",[t("li",[e._v("教材："),t("a",{attrs:{href:"http://incompleteideas.net/book/the-book-2nd.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://incompleteideas.net/book/the-book-2nd.html"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("代码："),t("a",{attrs:{href:"https://github.com/ShangtongZhang/reinforcement-learning-an-introduction",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://github.com/ShangtongZhang/reinforcement-learning-an-introduction"),t("OutboundLink")],1)])])]),e._v(" "),t("li",[e._v("Algorithms for Reinforcement Learning："),t("a",{attrs:{href:"https://sites.ualberta.ca/~szepesva/RLBook.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://sites.ualberta.ca/~szepesva/RLBook.html"),t("OutboundLink")],1)])])]),e._v(" "),t("li",[e._v("综述：\n"),t("ol",[t("li",[e._v("Deep Reinforcement Learning: Pong from Pixels："),t("a",{attrs:{href:"http://karpathy.github.io/2016/05/31/rl/",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://karpathy.github.io/2016/05/31/rl/"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("OpenAI Spinning Up - Part 1: Key Concepts in RL："),t("a",{attrs:{href:"https://spinningup.openai.com/en/latest/spinningup/rl_intro.html#part-1-key-concepts-in-rl",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://spinningup.openai.com/en/latest/spinningup/rl_intro.html#part-1-key-concepts-in-rl"),t("OutboundLink")],1)])])]),e._v(" "),t("li",[e._v("应用：\n"),t("ol",[t("li",[e._v("Robotics:\n"),t("ol",[t("li",[e._v("Stanford helicopter："),t("a",{attrs:{href:"http://heli.stanford.edu/",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://heli.stanford.edu/"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("......")])])]),e._v(" "),t("li",[e._v("Games:\n"),t("ol",[t("li",[e._v("Atari（雅达利）："),t("a",{attrs:{href:"https://deepmind.com/research/publications/playing-atari-deep-reinforcement-learning/",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://deepmind.com/research/publications/playing-atari-deep-reinforcement-learning/"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("AlphaGo（围棋）："),t("a",{attrs:{href:"https://deepmind.com/research/alphago/",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://deepmind.com/research/alphago/"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("AlphaStar（StarCraft II）："),t("a",{attrs:{href:"https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("OpenAI Five（Dota 2）："),t("a",{attrs:{href:"https://openai.com/blog/openai-five/",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://openai.com/blog/openai-five/"),t("OutboundLink")],1)])])]),e._v(" "),t("li",[e._v("NLP:\n"),t("ol",[t("li",[e._v("Deep Reinforcement Learning for Natural Language Processing："),t("a",{attrs:{href:"https://sites.cs.ucsb.edu/~william/papers/ACL2018DRL4NLP.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://sites.cs.ucsb.edu/~william/papers/ACL2018DRL4NLP.pdf"),t("OutboundLink")],1),e._v(" "),t("ul",[t("li",[e._v("Information Extraction")]),e._v(" "),t("li",[e._v("Relational Reasoning")]),e._v(" "),t("li",[e._v("Sequence Learning")]),e._v(" "),t("li",[e._v("Text Classification")]),e._v(" "),t("li",[e._v("Coreference Resolution")]),e._v(" "),t("li",[e._v("Summarization")]),e._v(" "),t("li",[e._v("Language and Vision\n"),t("ul",[t("li",[e._v("Video Captioning")]),e._v(" "),t("li",[e._v("Visual-Language Navigation")])])]),e._v(" "),t("li",[e._v("Multi-turn dialog")]),e._v(" "),t("li",[e._v("Text games："),t("a",{attrs:{href:"https://github.com/jvking/text-games",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://github.com/jvking/text-games"),t("OutboundLink")],1)])])]),e._v(" "),t("li",[e._v("News Recommendation："),t("a",{attrs:{href:"http://www.personal.psu.edu/~gjz5038/paper/www2018_reinforceRec/www2018_reinforceRec.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://www.personal.psu.edu/~gjz5038/paper/www2018_reinforceRec/www2018_reinforceRec.pdf"),t("OutboundLink")],1)])])]),e._v(" "),t("li",[e._v("Others:\n"),t("ol",[t("li",[e._v("AutoML："),t("a",{attrs:{href:"https://ai.googleblog.com/2017/05/using-machine-learning-to-explore.html?m=1",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://ai.googleblog.com/2017/05/using-machine-learning-to-explore.html?m=1"),t("OutboundLink")],1)])])])])]),e._v(" "),t("li",[e._v("人物\n"),t("ol",[t("li",[e._v("Richard Bellman")]),e._v(" "),t("li",[e._v("Lev Pontryagin")]),e._v(" "),t("li",[e._v("Andrew Barto")]),e._v(" "),t("li",[e._v("Richard Sutto："),t("a",{attrs:{href:"http://incompleteideas.net/",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://incompleteideas.net/"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Pieter Abbeel："),t("a",{attrs:{href:"https://www2.eecs.berkeley.edu/Pubs/Faculty/abbeel.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://www2.eecs.berkeley.edu/Pubs/Faculty/abbeel.html"),t("OutboundLink")],1)])])]),e._v(" "),t("li",[e._v("最新资讯\n"),t("ol",[t("li",[e._v("Berkeley RAIL："),t("a",{attrs:{href:"http://rail.eecs.berkeley.edu/publications.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://rail.eecs.berkeley.edu/publications.html"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("David Silver Publications："),t("a",{attrs:{href:"http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications.html"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("DeepMind Blog："),t("a",{attrs:{href:"https://deepmind.com/blog/",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://deepmind.com/blog/"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("OpenAI Blog："),t("a",{attrs:{href:"https://openai.com/blog/",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://openai.com/blog/"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("Arxiv Sanity："),t("a",{attrs:{href:"http://www.arxiv-sanity.com/search?q=reinforcement+learning",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://www.arxiv-sanity.com/search?q=reinforcement+learning"),t("OutboundLink")],1)]),e._v(" "),t("li",[e._v("University of Alberta: "),t("a",{attrs:{href:"https://spaces.facsci.ualberta.ca/rlai/",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://spaces.facsci.ualberta.ca/rlai/"),t("OutboundLink")],1)])])])])],1)},[],!1,null,null,null);r.default=a.exports}}]);